---
layout: post
title: Meet Chirag Gupta, GSoC 2025 Contributor Building an LLM for Jenkins Failure Diagnosis
tags:
  - gsoc
  - gsoc2025
  - jenkins
  - LLM
  - AI
  - fine-tuning
  - RAG
  - open-source
authors:
  - chiruu12
opengraph:
  image: /images/gsoc/opengraph.png
sig:
  - gsoc
---

Hello, Jenkins Community!

I'm Chirag Gupta, and I'm incredibly excited to announce that I've been selected for the Google Summer of Code 2025 program to work with the Jenkins project! It's an honor to contribute to such a cornerstone of the open-source CI/CD landscape.

My project, *"Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data,"* aims to create a specialized Large Language Model (LLM) to assist Jenkins users in diagnosing build failures more effectively. The core idea is to leverage the wealth of real-world data from `ci.jenkins.io` to fine-tune an LLM, making it adept at understanding Jenkins-specific issues. You can check out link:/projects/gsoc/2025/projects/domain-specific-LLM-based-on-jenkins-usage-using-ci-jenkins-io-data/[my project] for more details.

== Diving In: The Community Bonding Period

The past few weeks of the community bonding period have been an invaluable learning experience, focused on laying a solid foundation for the coding phases ahead:

* *Deep Dive into ci.jenkins.io Data:* The dataset is the lifeblood of the project. I've been exploring its structure, which includes a vast array of build logs, XML metadata (`build.xml`, `changelog.xml`, `config.xml`), and other artifacts. Understanding the sheer scale (approx. 400,000 files!) and the diversity within this data is crucial. My initial analysis, as outlined in my proposal, has focused on identifying key characteristics, potential challenges (like log noise and token inflation), and patterns that will inform our data preprocessing and fine-tuning strategies.

* *Understanding the Jenkins Ecosystem:* Beyond the data, I've been deepening my understanding of Jenkins CI/CD principles, common failure scenarios, and existing tools like the Build Failure Analyzer and Log Parser. This broader context is essential for building a truly useful LLM.

* *Collaboration with Mentors:* I've had insightful discussions with my mentors, Kris Stern, Shivay Lamba, Bruno Verachten, Harsh Pratap Singh, and Vutukuri Sreenivas. Their expertise and guidance have been instrumental in refining the project's technical roadmap, from model selection (exploring options like Phi-4 and Qwen) to planning our evaluation strategies.

The bonding period has truly highlighted the importance of high-quality, structured data for effective LLM training. The `ci.jenkins.io` dataset, with its real-world complexities, offers both a significant challenge and a fantastic opportunity.

== What Lies Ahead?

As we transition into the coding period, the immediate focus will be on:

* Implementing robust log cleaning and preprocessing pipelines.
* Systematically parsing metadata to create a comprehensive index of builds and their outcomes.
* Beginning the critical task of structuring the data into a format suitable for fine-tuning our chosen LLM, including generating QA pairs.
* Preparing for and executing the initial fine-tuning runs.

I'm incredibly excited to move forward and start bringing this project to life. I believe that an LLM tailored for Jenkins can significantly enhance the user experience by providing more intuitive and actionable insights into build issues, and also reduce the time taken by people to parse their build failures.

A heartfelt thank you to my mentors and the entire Jenkins community for this amazing opportunity and for the warm welcome. I'm eager to learn, contribute, and share my progress with all of you.

Let's build a smarter Jenkins together!
