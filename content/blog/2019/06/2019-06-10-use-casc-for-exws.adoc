---
layout: post
title: "Use Terraform with External Workspace Manager to Support EFS"
tags:
- jenkins
- gsoc
author: yufei_zhang
description: "A brief example of using Terraform with EFS" # optional
opengraph:
---

=== Why you want to use External Workspace Manager with EFS
What is Terraform : A CasC software, like CloudFormation and Ansible designed for managing cloud resources. It can free you from managing cloud resource by console, and can be version controlled using git as it is configuration-as-code. Currently it supports AWS and Azure best. AWS CloudFormation is for AWS only.
What is extenal-workspace-manager : It is a pipeline plugin which customizes the workspace path. The same disk can be mounted to multiple nodes to share resources
What is EFS : Amazon Elastic File System, an Network File System, can be shared among a lot of EC2 instances.

Who should read this blog :
. build Jenkins based on cloud, want to have good version control over all resources including infrastructure; 
. You want to share workspace among agents (slaves), there might be an upstream job creating a large file and don't want to copy it into downstream job's workspace because it's time-consuming; 
. You're afraid of running out of workspaces, and wants an extensible disk.

Who should not read this blog : 
. Skilled AWS architecture already using CasC tools
. Ops already using CasC and know how to provision EFS to a Jenkins node using user data.
. Running Jenkins in local physical machine, and do not build Jenkins based on Clouds.

What you'll want to do, is to learn external-workspace-manager directly to do similiar things, see blog link : link:https://github.com/jenkinsci/external-workspace-manager-plugin [External Workspace Manager]

This tutorial use AWS as example, but other clouds like Google Cloud, Microsoft Azure are also supported. (same mechanism, different syntax), and here we go.

=== Define a master Jenkins EC2

Terraform use its own DSL, but you don't need to worry about the syntaxes. You only need to know the concept of CasC, then you can use any CasC with any cloud providers or even other services.You create a ```jenkins.tf``` file, and then write such code :

```
provider "aws" {
  profile    = "default"
  region     = "us-east-1"
}

```
This setup the AWS account you want to use. See more detail on : link:https://www.terraform.io/intro/index.html [introduction on terraform]
```
resource "aws_instance" "jenkins_master" {
  ami           = "ami-174325867235"
  instance_type = "t2.micro"
  *user_data*    = "${data.template_file.jenkins_start_script}"
}
```
This defines a ec2 instance, and use a template we will define later as the user data. User data is a script to be executed when the instance is launched. We will use this user data to install dependencies, Jenkins, mount EFS and many other things.


```
resource "aws_efs_file_system" "jenkins_efs" {
  creation_token = "jenkins"
  tags = {
    Name = "jenkins-efs"
  }
}
```
This defines an EFS, we will use its id.
```
data "template_file" "jenkins_start_script" {
  template = "${file("${path.module}/jenkins_start_script.tpl")}"
  vars = {
    EFS_ID = "${aws_efs_file_system.jenkins_efs.private_ip}"
  }
}
```
This tells terraform to find a file named "jenkins_start_script.tpl" in the same directory with current .tf file, and feed the id of the EFS we just created to the variable 'EFS_ID'. It looks very much like function/methods in imperative languages, just pass in values to provision resources.Finally we write the installation script.

```
#!/bin/bash

# file named "jenkins_start_script.tpl"

yum update -y
yum update -y
yum install jenkins
systemctl start jenkins.service
yum install -y amazon-efs-utils
# then you mount the EFS

mount -t ${EFS_ID}:/ /home/jenkins/custom-workspace-path/

# then do other things
```
Now you have defined a EC2 instance with an EFS mounted. (But it's not created yet, you need to run some commands to actually create that, this is just like a blueprint)

=== Use auto scaling groups
Next steps would be defining auto-scaling-groups as slaves. The user-data part is almost the same, only that you need to put user data in the launch configuration of an auto scaling group.

```
resource "aws_autoscaling_group" "jenkins_slave_asg" {
  name                      = "jenkins-slave-asg"
  max_size                  = 5
  min_size                  = 2
  health_check_grace_period = 300
  health_check_type         = "ELB"
  desired_capacity          = 4
  force_delete              = true
  launch_configuration      = "${aws_launch_configuration.jenkins_slave_asg_launch_configuration.name}"
}

resource "aws_launch_configuration" "jenkins_slave_asg_launch_configuration" {
  name          = "jenkins-slave-asg-launch-configuration"
  image_id      = "ami-1571365314613"
  instance_type = "t2.micro"
  user_date     = ${data.template_file.jenkins_slave_start_script}"
}
```

You can write a new user data for Jenkins slaves, with the same syntax above. Defining those files are just drawing blueprints. We need to execute some Terraform commands to make things happen. Simply go to the directory you have your .tf file, install terraform if not installed before,  then execute : 
```
terraform init   # download needed resources
terraform plan   # output a plan of what's gonna be created, destoryed or changed of your AWS resources
terraform apply  # apply those changes, it requires a confirmation before it actually does something.
```
We just showed a brief example of using Terraform, but you might want to learn Terraform in a more detailed way, some resources are :
link:https://www.terraform.io/intro/index.html [Terraform Get Started]

=== Use ec2-plugin with EFS

Jenkins provides plugins that can automatically create slave agents with large flexibility. link:https://github.com/jenkinsci/ec2-plugin [ec2-plugin], and ecs-plugin allow you either use an normal ec2 instance or the managed Elastic Container Service provided by AWS to provision slaves. They have almost the same configurable entries with Terraform, but not as flexible as Terraform because in more complicated cases, you want to create inter-dependencies across multiple AWS resources, and Terraform is designed for that. But if you don't want your Jenkins be too complex, those plugins would be perfect choice for you to automate slaves. 

=== Jenkins CasC

Some large scale Jenkins cluster maintainers would complain it is hard to manage so many Jenkins instances. If any changes being made, one must go to Jenkins web UI page to click buttons. That would be a nightmare if you don't take it seriously, and require very high skill of keeping those configurations up-to-date. Now Jenkins community have realized that CasC's important role in modern Ops world. By using CasC you can version control your infrastructures, and would be extremely convenient if you want to migrate your environments. Recently our community are working on Jenkins configuration as code. If you install link:https://github.com/jenkinsci/configuration-as-code-plugin[configuration-as-code] plugin, you can write all your configurations into a file and feed it to Jenkins. This means, one day you can manage your Jenkins cluster easily without using any third-party tools. We will present more blogs about how to utilize JCasC together with clouds.




