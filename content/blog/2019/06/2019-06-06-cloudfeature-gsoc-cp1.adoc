---
layout: post
title: "GSoC Project Progress : Cloud features for external workspace manager"
tags:
- jenkins
- gsoc
author: yufei_zhang
description: "Short summary of coding period 1" # optional
opengraph:
---

=== About Me
My name is Yufei Zhang, a student from Zhejiang University and Simon Fraser University Dual Degree Program. I want to share the discoveries when we are exploring the possiblities of extending current external workspace manager plugin (referred to as EWM) to support AWS EFS. 

=== Backgrounds
For users, they might want to provision a high-available Jenkins cluster, together with other services such as Keycloak for SSO, and use k8s to autoscale agents. All these operations needs a lot of configuration and cloud resources if they decide to base Jenkins on clouds. 

In such cases, EWM was designed to give multiple agents access to shared disks, hence reduce the cost of copying duplicated data, such as codes and outputs in the workspace, or archives that needs to be managed by other services (e.g. Some companies have a ec2 instance running a cron job, pulling the Jenkins build artifacts and store in it S3). With these backgrounds, it is natural to think of "supporting cloud disks".

Our project proposal was based on extending cloud features, but then we discovered we were on the wrong track.

=== Discoveries
In order to make things clear, we need to understand the true nature of EWM. As we stated earlier, we want multiple agents to share disk spaces, and the main obstacle was they all have their own workspace directory (paths) by default. If we can modify the default workspace directory, then we might be able to utilize the shared NFS (Network File System).  And that is what EWM did. There are other features in like different strategies choosing a disk, but the way EWM to solve the problem is simple but effective.

And by the way, from my perspective,the main problem, synchronization when visiting shared resources like two slave visit the shared file, is guaranteed by the implementation of the NFS itself, and the EWM didn't offer any synchronization mechanism to support concurrent execution. Jenkins itself is not designed to be synchronized. It is left to the users to partition their jobs and let the user manage syncronization. There might be some tricks to do that, but not within the scope of this blog.

When we know what EWM did, we also realized : The Cloud feature is actually already supported. First, from the users perspective, they don't need to worry about the type of the disk, no matter it is a ext2 or ext3 or NFS or any other file system, they all look the same to host machine because of the concept of Virtual File System. If user can mount a disk to their host machine, then the EWM would be able to use them. So user can just create an EFS (Elastic File System, from AWS) in using whatever tools they like, and mount it. Then they can orchestra EFS with EWM.

Then the problem becomes, should Jenkins be responsible to manage the NFS, for example, creating/managing/mounting/destroying the AWS EFS ? Well, my answer is not. There are some reasons. We will use AWS as example, but the same for other cloud providers.

*Firstly*, for small users, they don't need anybody to manage their jenkins clusters. AWS console gives them a user-friendly to manage the resources, and that would be enough.

*Secondly*, for medium/large users, it is impossible for them to manage Cloud resources manually (by console). They must use some resource management tools, like CloudFormation by AWS and Terraform by Hashicorp. And me personally are using these tools to manange clusters with thousands of AWS resources. From my perspective, I would like all the resources managed in one place, then that would make me easy to find the problem if something been created/destroyed unexpectedly. I won't let a second participation in my relationship with AWS, as they might potentially ruin everything. e.g, sometimes I had to manage resources using console, but this is even considered as a dangerous operation. Therefore, this plugin should not and not bother to manage any cloud resources. (There are plugins like ec2-plugin who do, but they are well managed, which is safe and used a lot).

For example, when using terraform, we would create an EFS using
```
resource "aws_efs_file_system" "efs_jenkins" {
  encrypted      = false
  
	
  tags = {
    Name = "Jenkins EFS"
  }
}
```
Then you would add some mount targets using the same syntax, we skip that here. Finally, you want want to lauch an auto-scaling group or single ec2 instance, and the you write a script like installing the Jenkins in the user data, and all other bootstrap settings.

You have a user data file called `jenkins-bootstrap.tpl`, like this
```
# assume all dependencied installed
sudo yum update -y
sudo yum install jenkins
sudo systemctl start jenkins.service
sudo yum install -y amazon-efs-utils
# then you mount the EFS

sudo mount -t ${EFS_ID}:/ ${MOUNT_POINT}
```
Then you create a ec2 instance with such statement
```
resource "aws_instance" "jenkins" {
  ami           = "${data.any_ami_you_want}"
  instance_type = "t2.micro"
  user_date     = 
  tags = {
    Name = "HelloWorld"
  }
}


data "template_file" "jenkins_init" {
  template = "${file("${path.module}/jenkins-bootstrap.tpl")}"
  vars = {
    EFS_ID        = "${aws_efs_file_system.efs_jenkins.id}"
    MOUNT_POINT   = "${var.mount_point}"
  }
}
```

As you can see, user needn't know the efs-id of the created system, just build a dependency like this, and everything is set up automatically. 

*Thirdly*, no convenience is given to user, even we implement the cloud management. If we only implement EFS support, there are many more AWS resources, like IAM role, security groups, and the user still needs to worry about those elsewhere, and if we cannot implement all, we better implement none of them. The point we want to address is, user better give control of AWS resources to as few softwares as possible. if resource A is managed by Jenkins, B by Ansible, C by CloudFormation, and D by Terraform, it would be a disaster to manage.

So you can see, the user can do the exactly same thing we want to implement, using other tools and current EWM, possibly in a better way. Then we find that, though I personally did quite a lot to this idea, like learning AWS and Jenkins plugin developement and some working codes, we have to admit our idea might not provide any new benefit.

=== Done and TODOs
This is what we've already done:

. The Web UI to define a AWS EFS disk
. Implemented a demo workflow code
. Implemented the AWS EFS utils, like creating, destroying, mounting an EFS.

And unfortunately we need to give up those work. We realize sometimes negative results are also results. A good programmer should know when he is wrong, and has the courage to admit it. Honestly, we were a little bit uneasy when we did the decision, but it doesn't matter, we will continue and spend time on something else.

=== Plan for the future

I previously worked with the JCasC compatiblity of EWM, and my lead mentor Martin, is also interested in JCasC. Then we talked with Oleg and agree JCasC would be a good project to work on. Now we want to have a meeting with stakeholders to decide the priorities of which plugins should we work on first. Also, JCasC is somehow the extension of cloud features, as CasC is important in managing large clusters, if we do more work on JCasC, the integrations of Jenkins and clouds would also be promoted. And that is what we want to see.

=== Meeting summary
   



