---
layout: post
title: "Define your environment with Docker Pipeline, don't install software"
tags:
- jenkins
- dsl
- pipeline
- plugins
- blueocean
- ux
- javascript
- nodejs
author: michaelneale
---

If you are running parts of your pipeline on Linux, possibly the easiest way to get 
a clean reusable environment is to use: link:https://go.cloudbees.com/docs/cloudbees-documentation/cje-user-guide/chapter-docker-workflow.html[Docker Pipeline].

In this short post I wanted to show how you can avoid installing stuff on the agents, and have per project, or even per branch, customized build environments. 
Your environment, as well as your pipeline is defined and versioned alongside your code. 

This is used in the "dogfood" project for Blue Ocean. (see link:https://en.wikipedia.org/wiki/Eating_your_own_dog_food[eating own dogfood]). Some call it "drinking your own Champagne" but unless you live in France technically you can't say that.


=== Environment and Pipeline for Javascript components

The link:/doc/blueocean[Blue Ocean] project has a few moving parts, one of which is called the "Jenkins Design Language". 
This is a grab bag of re-usable css, html, style rules, icons and javascript components (using React.js) that provide the look and feel that 
makes Blue Ocean look the way it does (it's intention isn't to be Blue Ocean specific).

Javascript and the web being what it is in 2016, it is in need of various tooling. 
This includes npm and all that it needs. Less to convert less to css, Babel to "transpile" versions of Javascript to other types of Javascript (don't ask) and more. 

We could spend time installling nodejs/npm on the agents, but why not just use the link:https://hub.docker.com/_/node/[official off the shelf] docker image from docker hub? 

This way the only thing that has to run on the build agents, is the Jenkins agent, and a docker daemon. This gave a good start of a pipeline in the `Jenkinsfile` in the root of the repo:

[source,groovy]
----
node {
        stage "Prepare environment"
          checkout scm
          docker.image('node').inside {
            stage "Checkout and build deps"
                sh "npm install"

            stage "Test and validate"
                sh "npm install gulp-cli && ./node_modules/.bin/gulp"                
          }
}
----


=== Customising the environment, without installing bits on the agent

Being the forward looking and lazy person that I am, I didn't want to have to go and fish around for a Docker image every time
a developer wanted something special installed. 

Instead I put a `Dockerfile` in the root of the repo, alongside the `Jenkinsfile`:

image::/images/post-images/2016-08-03/environment_jenkinsfile.png[Environment, role="center"]

The contents of the `Dockerfile` can then define the exact needs of the environment. 
Sure enough, shortly after this, someone came along saying they wanted to use link:https://flowtype.org/[Flow] from Facebook (A typechecker for Javascript).
This required some additional native component to work (via apt-get install). 

This was achieved via a link:https://github.com/jenkinsci/jenkins-design-language/pull/72/files[pull request] to both the Jenkinsfile and the Dockerfile at the same time. 

So now our environment is defined by a `Dockerfile` with the following contents: 
[source,shell]
----
# Lets not just use any old version but pick one
FROM node:5.11.1

# This is needed for flow, and the weirdos that built it in ocaml:
RUN apt-get update && apt-get install -y libelf1

RUN useradd jenkins --shell /bin/bash --create-home
USER jenkins
----

The `Jenkinsfile` pipeline now has the following contents: 
[source,groovy]
----
node {
    stage "Prepare environment"
        checkout scm
        def environment  = docker.build 'cloudbees-node'

        environment.inside {
            stage "Checkout and build deps"
                sh "npm install"

            stage "Validate types"
                sh "./node_modules/.bin/flow"

            stage "Test and validate"
                sh "npm install gulp-cli && ./node_modules/.bin/gulp"
                step([$class: 'JUnitResultArchiver', testResults: 'reports/**/*.xml'])
        }

    stage "Cleanup"
        deleteDir()
}
----

TIP: Even hip Javascript tools can emit that weird XML format that test reporters can use, eg the junit result archiver.

The main change is that we have `docker.build` being called to produce the `environment` which is then used. 
Running docker build is essentially a "no-op" if the image has already been built on the agent before.

=== What's it like to drive? 

Well, using Blue Ocean, to build Blue Ocean, yields a pipeline that visually looks like this (a recent run I screen capped): 

image::/images/post-images/2016-08-03/JDL_pipeline.png[Pipeline, role="center"]

This gives a pipeline that developers can tweak on a pull-request basis, along with any changes to the environment needed to support it, without having to install any packages on the agent. 

TIP: Jenkins pipeline keeps track of docker images used in a Dockerfile (which is good, should that image need to change due to a security patch).
